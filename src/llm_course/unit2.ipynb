{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa76772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0714d33f3f94153aeba92690ead7cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5b343efb55414994f1248db359b917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707acc02241e41e98d5e7f3218355751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883527d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "torch.Size([2, 16])\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "print(inputs[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1de5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f442bb98c549658ee1a316621735ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950cde21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a51a3b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe082bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1a277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0195e-02, 9.5980e-01],\n",
      "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d06b4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f2c052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fdb75de8bf4b929147d260576f4bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb2c7662b1a49d0a99316909c66dbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b09b5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6ad69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./my_bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fadce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"./my_bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "291b3177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756cded2e3e441ba95c9b94cbb3b3630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe354062c08d4e6fa6df018c54d67fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5070c7016de54f6188d715b0ac4fa732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 8667, 117, 146, 112, 182, 170, 1423, 5650, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "encoded_input = tokenizer(\"Hello, I'm a single sentence!\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50df803b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Hello, I ' m a single sentence! [SEP]\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb50e84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1731, 1132, 1128,  136,  102,    0,    0,    0,    0],\n",
      "        [ 101,  146,  112,  182, 2503,  117, 6243, 1128,  106,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\n",
    "    [\"How are you?\", \"I'm fine, thank you!\"], padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b0e2e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 1188, 1110,  170, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304,\n",
      "         1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304,\n",
      "         1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304,\n",
      "         1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304,\n",
      "         1304, 1304, 1304, 1304, 1304, 1263, 5650,  119,  102]])\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\n",
    "    \"This is a very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very long sentence.\",\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "print(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09c36ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0670,  0.0823,  0.0978,  ...,  0.1587,  0.4152,  0.1319],\n",
       "         [-0.5355,  0.0667,  0.4521,  ...,  0.4082,  0.2620,  0.6243],\n",
       "         [ 0.0079,  0.2364,  0.3596,  ...,  0.3751,  0.2850,  0.3106],\n",
       "         ...,\n",
       "         [ 0.2369,  0.3415,  0.2226,  ...,  0.1824,  0.4344,  0.6573],\n",
       "         [ 0.0474,  0.3143,  0.2073,  ..., -0.2330,  0.3486, -0.0121],\n",
       "         [-0.7716,  1.3391, -0.5035,  ...,  0.8173,  1.0006, -0.1437]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-8.4987e-01,  6.0311e-01,  9.9999e-01, -9.9764e-01,  9.8400e-01,\n",
       "          6.0474e-01,  9.9392e-01, -8.9892e-01, -9.8765e-01, -7.7924e-01,\n",
       "          9.9445e-01,  9.9956e-01, -9.8707e-01, -9.9995e-01,  1.8453e-01,\n",
       "         -9.9090e-01,  9.9691e-01, -6.8533e-01, -9.9999e-01, -5.5970e-01,\n",
       "         -3.0071e-01, -9.9998e-01,  3.5653e-01,  9.2926e-01,  9.9239e-01,\n",
       "          2.2756e-02,  9.9586e-01,  9.9999e-01,  8.9937e-01,  3.4431e-01,\n",
       "          4.4170e-01, -9.9678e-01,  3.8121e-01, -9.9972e-01,  2.3676e-01,\n",
       "         -2.1421e-01,  5.3001e-02, -3.4197e-01,  7.2836e-01, -8.9802e-01,\n",
       "         -8.8124e-01, -2.9570e-01,  2.6271e-01, -6.4795e-01,  6.4656e-01,\n",
       "          5.9562e-01,  3.6834e-01, -7.4532e-02, -2.0265e-01,  9.9999e-01,\n",
       "         -9.8964e-01,  1.0000e+00, -9.6516e-01,  9.9990e-01,  9.9849e-01,\n",
       "          7.3284e-01,  9.9854e-01,  3.5856e-01, -9.8133e-01,  6.8408e-01,\n",
       "          9.8677e-01,  1.3132e-01,  9.7665e-01, -4.9960e-01, -1.3144e-01,\n",
       "         -6.7979e-01, -7.2101e-01,  3.3247e-01, -5.9259e-01,  7.0839e-01,\n",
       "          4.8435e-01,  3.5517e-01,  9.9513e-01, -9.5269e-01, -1.7549e-01,\n",
       "         -9.6845e-01,  3.9844e-01, -9.9998e-01,  9.7729e-01,  9.9999e-01,\n",
       "          1.1438e-01, -9.9990e-01,  9.9857e-01, -3.3576e-01, -2.6987e-01,\n",
       "         -2.5719e-01, -9.9106e-01, -9.9983e-01,  2.0462e-01, -8.0382e-01,\n",
       "          8.3573e-01, -9.9654e-01,  3.5586e-01, -6.2468e-01,  9.9999e-01,\n",
       "         -7.5642e-01, -3.1695e-01,  4.7083e-01,  8.5792e-01,  4.8042e-02,\n",
       "         -9.1958e-01,  7.7082e-01,  9.8966e-01, -9.5579e-01,  9.8935e-01,\n",
       "          1.1235e-01, -9.7189e-01, -6.7519e-01,  1.5133e-01,  1.3943e-01,\n",
       "          9.9641e-01, -9.9778e-01, -5.1577e-01,  1.9323e-01,  8.1526e-01,\n",
       "         -8.3516e-01,  9.9519e-01,  4.9942e-01, -3.8169e-01,  1.0000e+00,\n",
       "         -2.3903e-01,  8.3223e-01,  9.9952e-01,  3.0248e-01, -3.3411e-01,\n",
       "         -3.5747e-01, -2.4838e-02,  6.8065e-01,  1.5077e-02, -7.9057e-01,\n",
       "          8.8427e-01, -9.9757e-01, -9.8224e-01,  9.9988e-01, -3.4864e-01,\n",
       "          9.9999e-01, -9.9977e-01,  9.5375e-01, -9.9999e-01, -3.6096e-01,\n",
       "         -2.2426e-01, -7.4468e-02, -9.3145e-01,  4.9642e-01,  9.9732e-01,\n",
       "          1.7684e-01, -7.2909e-01,  9.0272e-04,  7.5324e-02, -3.3944e-01,\n",
       "          7.5082e-01,  9.0687e-01, -9.8603e-01,  9.9998e-01,  9.8004e-01,\n",
       "          8.5680e-01,  9.3085e-01,  2.1877e-01, -8.2474e-01,  6.8423e-01,\n",
       "          9.9447e-01, -9.9980e-01,  7.4356e-01, -9.5976e-01,  9.9988e-01,\n",
       "          9.9068e-01,  4.8733e-01, -9.5635e-01,  9.9998e-01,  5.7187e-02,\n",
       "          1.3546e-01, -3.1167e-01, -4.0512e-01, -9.8945e-01,  5.2421e-01,\n",
       "          4.6335e-01,  9.3258e-01,  9.9992e-01, -9.9792e-01,  9.9995e-01,\n",
       "          9.9936e-01, -2.9811e-01,  9.2352e-01,  9.8716e-01, -9.9880e-01,\n",
       "         -9.9450e-01, -9.9634e-01,  5.1549e-01, -1.0024e-01,  4.6329e-01,\n",
       "         -5.2012e-02,  9.8754e-01,  9.8894e-01,  8.4682e-01, -9.9952e-01,\n",
       "         -4.2371e-01,  9.9269e-01, -1.6929e-01,  9.9999e-01,  1.6431e-01,\n",
       "         -9.9995e-01, -2.7570e-01,  7.5588e-01,  9.6348e-01, -3.7452e-01,\n",
       "          9.8831e-01, -1.5099e-01,  2.3411e-01,  9.2342e-01, -9.9999e-01,\n",
       "          9.7298e-01, -1.2343e-02,  2.6922e-01,  9.1943e-01,  9.9794e-01,\n",
       "         -4.2563e-01, -7.9113e-02,  3.6519e-01, -3.7304e-01,  9.9998e-01,\n",
       "         -9.9987e-01, -2.5311e-01,  7.7466e-01, -9.9875e-01, -9.9921e-01,\n",
       "          9.9261e-01, -1.6225e-01, -1.5908e-01, -4.3697e-01, -6.9463e-01,\n",
       "          3.3410e-01,  7.6430e-01,  9.9646e-01, -2.2608e-01,  1.7577e-01,\n",
       "         -9.9997e-01, -9.5913e-01, -9.6178e-01, -8.5725e-01, -2.3869e-03,\n",
       "          7.0874e-01, -4.9432e-01, -9.7382e-01, -9.8366e-01,  9.7926e-01,\n",
       "          3.5205e-01, -6.8349e-01, -5.3114e-01, -4.5401e-02, -9.8623e-01,\n",
       "         -8.3677e-02, -6.5280e-01, -9.9966e-01,  9.9988e-01, -4.4841e-02,\n",
       "          9.7806e-01,  9.9159e-01, -9.9832e-01,  4.8201e-01, -9.8413e-01,\n",
       "         -1.8063e-01, -9.9999e-01,  2.8729e-02,  6.5512e-02,  6.4518e-03,\n",
       "         -2.3818e-01,  9.9714e-01, -9.8520e-01, -3.7152e-01,  6.1245e-01,\n",
       "         -9.9997e-01,  9.6723e-01, -4.1828e-01,  9.9963e-01,  6.1599e-01,\n",
       "          2.9835e-01,  9.9582e-01,  7.8144e-01, -9.9543e-01, -9.9997e-01,\n",
       "          8.7753e-01,  9.9986e-01, -9.9841e-01, -2.1911e-01,  9.9998e-01,\n",
       "         -9.8057e-01, -9.5453e-01, -9.7977e-01, -9.9829e-01, -9.9991e-01,\n",
       "          7.9625e-02, -3.7209e-01, -9.0446e-02,  9.9466e-01, -7.2321e-02,\n",
       "          4.0840e-02,  9.9742e-01,  9.9980e-01,  1.1763e-01,  1.1724e-01,\n",
       "          5.3399e-02, -9.9056e-01, -9.9995e-01,  5.5037e-01,  3.4044e-01,\n",
       "         -9.9999e-01,  9.9995e-01, -9.9789e-01,  1.0000e+00,  4.8453e-01,\n",
       "         -9.4285e-01,  9.1702e-01,  2.8797e-02, -8.6369e-01,  8.6482e-02,\n",
       "          9.9998e-01,  9.9408e-01, -2.9788e-01,  2.2206e-01,  5.1620e-01,\n",
       "         -7.7384e-02,  1.5987e-01, -4.1430e-01, -2.3405e-01,  3.6932e-01,\n",
       "         -9.6684e-01,  9.5596e-01,  1.1724e-01, -9.9747e-01,  9.8183e-01,\n",
       "          1.8322e-01,  9.3056e-01, -4.5030e-01,  9.6482e-01,  9.9686e-01,\n",
       "         -1.4348e-01,  1.5023e-01, -3.8185e-01, -9.9357e-01, -9.0392e-01,\n",
       "          3.7183e-01, -9.8486e-01,  4.5484e-02,  8.6867e-01,  9.9487e-01,\n",
       "         -9.8727e-01,  9.9983e-01, -2.4789e-01,  8.1542e-01, -9.8294e-01,\n",
       "          1.0000e+00, -9.9977e-01,  3.5419e-01,  3.9299e-01, -5.2922e-01,\n",
       "          2.7839e-01,  9.9800e-01,  8.9717e-01,  9.0535e-01, -9.1660e-01,\n",
       "         -5.1602e-01,  8.6654e-01,  9.8991e-01, -9.2918e-01,  8.5103e-02,\n",
       "         -9.9214e-01,  5.2010e-02,  9.9932e-01,  9.6130e-01, -1.4432e-01,\n",
       "         -6.4448e-01, -9.7836e-01,  9.8248e-01, -4.6642e-01, -7.6178e-01,\n",
       "         -2.5542e-01, -4.7003e-01,  5.0938e-01,  9.8704e-01, -1.5513e-01,\n",
       "          6.3405e-01,  2.5276e-01, -9.9543e-01,  7.7844e-01,  6.4336e-01,\n",
       "          9.9994e-01, -9.9275e-01, -8.3262e-02,  9.9632e-01, -2.6401e-01,\n",
       "         -5.3747e-01,  7.9901e-01,  9.8885e-01, -9.6557e-01, -3.3726e-01,\n",
       "         -9.9988e-01,  1.8999e-01, -7.7286e-01,  2.1094e-01, -1.4059e-01,\n",
       "          1.9483e-01, -4.2310e-01,  8.8809e-01, -4.4150e-01,  9.3291e-01,\n",
       "          1.0547e-01,  9.9065e-01,  3.6190e-01, -1.5626e-01, -4.3480e-01,\n",
       "          1.9499e-01,  5.2402e-01, -8.1973e-02,  9.9547e-01, -9.9017e-01,\n",
       "          9.9998e-01, -5.9775e-01, -9.9999e-01, -9.7545e-01, -1.8844e-01,\n",
       "         -9.9997e-01,  2.4929e-01, -9.9977e-01,  9.9457e-01,  5.6662e-01,\n",
       "         -9.8550e-01, -9.9196e-01, -9.9991e-01, -9.9998e-01,  6.6275e-01,\n",
       "         -6.5381e-02, -1.6834e-01, -1.5887e-01,  9.9228e-01,  2.1748e-01,\n",
       "          4.4925e-01, -1.7061e-01, -9.7524e-01,  3.5908e-02, -9.8121e-01,\n",
       "          4.5630e-01, -9.9999e-01, -2.3716e-01,  9.8218e-01, -9.7194e-01,\n",
       "         -8.6128e-01, -9.7025e-01, -1.7473e-01, -9.2518e-01,  6.9749e-01,\n",
       "          9.9505e-01,  1.4774e-02, -2.3869e-01, -9.9997e-01,  9.9794e-01,\n",
       "         -4.8589e-01,  1.9643e-01, -7.0109e-01, -9.9314e-01,  9.9995e-01,\n",
       "          4.7089e-01, -1.8401e-01, -1.3142e-01, -9.9982e-01,  9.4466e-01,\n",
       "         -7.8270e-01, -8.0781e-01, -9.9521e-01,  2.8765e-01, -9.8303e-01,\n",
       "         -9.9997e-01, -6.8545e-02,  9.7153e-01,  9.9974e-01,  9.9371e-01,\n",
       "          7.4030e-01, -3.7918e-01, -9.8028e-01,  1.3833e-01, -9.9999e-01,\n",
       "          2.9704e-01,  4.8389e-01, -9.9368e-01, -1.7257e-01,  9.9709e-01,\n",
       "          9.9192e-01, -7.6722e-01, -9.4688e-01,  6.4498e-01,  5.0849e-01,\n",
       "          9.8930e-01,  9.1593e-02, -7.3543e-01,  4.3534e-01, -8.0981e-02,\n",
       "         -9.9803e-01, -9.8306e-01,  9.9890e-01, -9.9098e-01,  9.9244e-01,\n",
       "          9.7824e-01,  9.8777e-01, -5.2588e-02, -2.1468e-01, -9.4236e-01,\n",
       "         -9.9997e-01, -8.0068e-01,  9.2562e-03, -9.9998e-01,  9.9999e-01,\n",
       "         -9.9999e-01,  1.6909e-01, -9.6902e-02,  6.1222e-01,  9.9607e-01,\n",
       "          9.4293e-02, -9.9998e-01, -9.9997e-01, -2.0862e-01,  6.1710e-03,\n",
       "          9.9714e-01,  1.3865e-02,  3.5566e-01, -9.4021e-02,  3.8880e-01,\n",
       "          9.9923e-01, -1.2909e-01,  1.2220e-01, -9.7665e-01,  9.9992e-01,\n",
       "          6.9283e-01, -9.9943e-01,  9.7642e-01, -9.9991e-01,  6.0180e-01,\n",
       "          9.8404e-01,  9.7282e-01,  9.9498e-01, -9.8879e-01,  9.9999e-01,\n",
       "         -9.9998e-01,  9.9985e-01, -1.0000e+00, -9.8709e-01,  9.9996e-01,\n",
       "         -9.9737e-01, -2.2930e-01, -9.9992e-01, -9.8686e-01, -4.0978e-02,\n",
       "          2.8795e-01, -7.0876e-01,  9.9728e-01, -9.9996e-01, -9.9952e-01,\n",
       "         -8.5969e-02, -6.5986e-01, -2.8699e-01,  9.6831e-01, -2.2876e-01,\n",
       "          9.9623e-01, -1.3159e-01,  9.8693e-01,  3.1919e-01,  9.8145e-01,\n",
       "          9.9999e-01, -5.2596e-01, -4.8901e-01, -9.9794e-01,  9.9770e-01,\n",
       "         -1.0285e-01,  5.1082e-01,  9.9326e-01, -5.0607e-02, -6.1029e-01,\n",
       "          6.4531e-01, -9.9897e-01,  4.2106e-01, -9.5393e-01,  7.5940e-01,\n",
       "          7.5561e-01,  8.8568e-01,  4.2025e-02, -4.3292e-01, -1.4927e-01,\n",
       "         -9.9809e-01,  5.2012e-01, -9.9989e-01,  9.9282e-01, -8.3863e-01,\n",
       "          1.8402e-01, -5.8415e-01,  6.3781e-01, -9.6194e-01,  9.9992e-01,\n",
       "          9.9964e-01, -1.0000e+00,  2.7861e-01,  9.9635e-01, -1.0929e-01,\n",
       "          9.9274e-01, -9.9814e-01, -8.9821e-02,  9.1288e-01, -8.1042e-01,\n",
       "          9.9571e-01,  3.7684e-01, -2.6048e-01,  9.9358e-01, -9.9835e-01,\n",
       "         -6.8086e-01, -8.9621e-01,  2.0503e-01,  5.4685e-01, -9.9034e-01,\n",
       "          2.4657e-01,  9.0352e-01, -2.3490e-01, -9.9991e-01,  7.6592e-01,\n",
       "         -9.9987e-01, -3.6201e-01,  9.9511e-01,  1.6959e-01,  9.9998e-01,\n",
       "         -3.5749e-01,  1.8371e-02, -5.2408e-02, -9.9994e-01, -9.8957e-01,\n",
       "          2.0913e-01, -3.7564e-01, -5.9471e-01,  9.9240e-01,  2.2941e-01,\n",
       "          2.9562e-01, -9.9999e-01,  3.9228e-01,  9.7874e-01,  3.9815e-01,\n",
       "          9.3619e-01, -2.5982e-01, -9.8682e-01, -8.7605e-01, -8.2974e-01,\n",
       "          1.6519e-01,  5.2696e-01, -9.6552e-01, -3.2142e-01, -7.0650e-01,\n",
       "          9.9999e-01, -9.9898e-01, -9.5787e-01, -9.9743e-01,  2.1972e-01,\n",
       "          6.6901e-01,  5.4226e-01,  9.3939e-03, -4.2371e-01,  7.7630e-01,\n",
       "         -7.6191e-01,  9.9893e-01, -9.9849e-01, -9.9890e-01,  9.9996e-01,\n",
       "          1.9486e-02, -9.5943e-01,  1.8385e-02, -4.6205e-01,  1.0633e-01,\n",
       "          1.1895e-02,  4.2821e-01, -8.1510e-01, -3.2995e-01, -9.9986e-01,\n",
       "          4.7097e-01, -3.6298e-01, -9.9553e-01, -8.2983e-01, -4.4941e-01,\n",
       "         -9.9999e-01,  9.9805e-01,  9.8937e-01,  9.9999e-01, -9.9995e-01,\n",
       "          9.4718e-01,  2.2411e-01,  9.9971e-01, -9.2810e-02, -6.9067e-01,\n",
       "          6.2513e-01,  9.9992e-01, -1.6692e-01,  5.3753e-01, -1.0989e-03,\n",
       "         -1.7609e-01,  2.0682e-01, -6.4025e-01,  9.7077e-01, -7.5241e-01,\n",
       "          5.5269e-01, -9.9401e-01, -9.9999e-01,  9.9998e-01, -2.3837e-01,\n",
       "          9.9734e-01,  4.3781e-01,  3.5767e-02, -9.5515e-01,  9.4054e-01,\n",
       "         -9.3485e-01, -9.7815e-01, -1.0000e+00,  5.9017e-01, -1.0000e+00,\n",
       "         -9.9743e-01,  1.7265e-01,  9.9653e-01, -9.9990e-01, -9.9649e-01,\n",
       "         -2.3553e-01, -1.0000e+00,  7.8860e-01, -9.5710e-01, -4.4222e-01,\n",
       "         -9.9526e-01,  9.7734e-01, -5.0954e-01,  2.7994e-01,  9.9020e-01,\n",
       "         -9.9088e-01,  7.9684e-01,  7.5893e-01,  9.7669e-01,  2.9920e-01,\n",
       "          2.6541e-01, -4.7875e-01, -9.7793e-01, -7.7911e-01, -9.8837e-01,\n",
       "          4.3721e-01, -9.9668e-01, -8.6847e-01,  9.9908e-01,  9.9681e-01,\n",
       "         -9.9990e-01, -9.9859e-01,  9.6481e-01, -1.7483e-01,  9.9633e-01,\n",
       "         -7.0819e-01, -9.9997e-01, -9.9998e-01,  2.7657e-01, -2.6912e-01,\n",
       "          9.9816e-01, -3.9012e-01,  9.9998e-01,  9.0679e-01,  4.6654e-02,\n",
       "          5.2328e-02, -1.9938e-01,  1.2412e-01, -4.3280e-02, -2.4604e-01,\n",
       "          9.9999e-01, -3.6302e-01,  9.9582e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb65d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
