{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2883e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e610509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvaknin34\u001b[0m (\u001b[33mvaknin34-hugging-face\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10a0d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"mlabonne/smoltldr\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "183d55ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBREDDIT: r/tifu\n",
      "\n",
      "TITLE: TIFU by trying to pet a dog.\n",
      "\n",
      "POST: Last night I went to a Hippie May Day Festival/ Camp out. Needless to say, I passed out hard in my tent at the end of the night.Woken by the warmth and light of the morning sun, I emerged from my tent in search of some water to quench my burgeoning thirst. To my delight I spotted a dog scouting the field before me, about 110 meters away. Without delay I dashed towards it, my urge to pet this dog was immeasurable. On the way back to my tent, while running, I just so happened to come upon the most heinous stick I have ever encountered. The bastard was sticking straight out of the earth, cleverly hidden in a plush, verdant meadow. My foot never saw it coming. It had no warning, no shoe, no defense! The poor soul (no pun intended) never saw it coming, until the moment it was impaled by what I would have thought was the devils pitchfork itself. The worst part is, I didn't even get to pet the dog, it sprinted back to it's owners property when it saw me approaching.\n",
      "\n",
      "TL;DR:\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf760fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tried to pet a dog, foot got impaled by a demon stick, never even got to pet the dog.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0][\"completion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0baf044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side='left')\n",
    "\n",
    "# Add padding token if it doesn't exist\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a84dcfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd17d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the baseline for both metrics we will optimize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# The output model should the same length as the answer\n",
    "def same_length(prompts, completions, answers, **kwargs):\n",
    "    # Reward for 2/difference in length\n",
    "    return [2 / (abs(len(completion) - len(answer)) + 1) for completion, answer in zip(completions, answers)]\n",
    "\n",
    "# Semantic similarity using embeddings\n",
    "# Load a pre-trained sentence transformer model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device=\"mps\")\n",
    "def semantic_similarity_embeddings(prompts, completions, answers, **kwargs):\n",
    "    # Get embeddings for completions and answers\n",
    "    completion_embeddings = embedding_model.encode(completions, convert_to_tensor=True)\n",
    "    answer_embeddings = embedding_model.encode(answers, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity between embeddings\n",
    "    cosine_scores = F.cosine_similarity(completion_embeddings, answer_embeddings, dim=-1).tolist()\n",
    "    return cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fddcc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5907be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating completions:   0%|          | 0/2 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating completions:  50%|█████     | 1/2 [01:45<01:45, 105.30s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Generating completions: 100%|██████████| 2/2 [03:29<00:00, 104.81s/it]\n",
      "Generating completions: 100%|██████████| 2/2 [03:29<00:00, 104.81s/it]\n"
     ]
    }
   ],
   "source": [
    "prompts = dataset[\"test\"][\"prompt\"]\n",
    "answers = dataset[\"test\"][\"completion\"]\n",
    "\n",
    "# Generate completions in batches for efficiency\n",
    "batch_size = 100\n",
    "completions = []\n",
    "for i in tqdm(range(0, len(prompts), batch_size), desc=\"Generating completions\"):\n",
    "    batch_prompts = prompts[i:i+batch_size]\n",
    "    batch_completions = text_generator(batch_prompts, do_sample=False, batch_size=batch_size)\n",
    "    completions.extend([output[0][\"generated_text\"] for output in batch_completions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eef9e6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same length score: 0.0022290948449059946\n",
      "Cosine similarity score: 0.577838778346777\n"
     ]
    }
   ],
   "source": [
    "# Compute same length scores\n",
    "same_length_score = same_length(prompts, completions, answers)\n",
    "print(f\"Same length score: {sum(same_length_score) / len(same_length_score)}\")\n",
    "\n",
    "# Compute cosine similarity scores\n",
    "cosine_scores = semantic_similarity_embeddings(prompts, completions, answers)\n",
    "print(f\"Cosine similarity score: {sum(cosine_scores) / len(cosine_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68c1c277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 9,768,960 || all params: 144,283,968 || trainable%: 6.7706\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load LoRA\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    target_modules=\"all-linear\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20ba9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=\"GRPO\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,  # Reduced batch size for stability\n",
    "    gradient_accumulation_steps=4,  # Increased to maintain effective batch size\n",
    "    max_prompt_length=512,\n",
    "    max_completion_length=96,\n",
    "    num_generations=4,  # Reduced for stability\n",
    "    bf16=False,  # Keep False for MPS\n",
    "    fp16=False,  # Ensure no mixed precision on MPS\n",
    "    dataloader_pin_memory=False,  # Disable pin_memory for MPS\n",
    "    report_to=[\"wandb\"],\n",
    "    remove_unused_columns=False,\n",
    "    logging_steps=1,\n",
    "    max_steps=100,  # Reduced for testing\n",
    "    label_names=[\"completion\"],\n",
    "    temperature=0.7,  # Add temperature for more stable generation\n",
    "    top_p=0.9,  # Add nucleus sampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6286732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class NaNGuardCallback:\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        for k, v in state.log_history[-1].items():\n",
    "            if isinstance(v, (float, int)):\n",
    "                if not math.isfinite(v):\n",
    "                    raise RuntimeError(f\"⚠️  {k} became {v} at step {state.global_step}\")\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        print(\"NaNGuardCallback initialized. Monitoring for NaN values during training.\")\n",
    "    def on_init_end(self, args, state, control, **kwargs):\n",
    "        print(\"NaNGuardCallback initialized. Monitoring for NaN values during training.\")\n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        print(\"Epoch started. Monitoring for NaN values during training.\")\n",
    "    def on_step_begin(self, args, state, control, **kwargs):\n",
    "        print(\"Step started. Monitoring for NaN values during training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eaab4e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNGuardCallback initialized. Monitoring for NaN values during training.\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    reward_funcs=[same_length, semantic_similarity_embeddings],\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    processing_class=tokenizer,\n",
    "    callbacks=[NaNGuardCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b9e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crisp-plant-7</strong> at: <a href='https://wandb.ai/vaknin34-hugging-face/GRPO/runs/xf7030bq' target=\"_blank\">https://wandb.ai/vaknin34-hugging-face/GRPO/runs/xf7030bq</a><br> View project at: <a href='https://wandb.ai/vaknin34-hugging-face/GRPO' target=\"_blank\">https://wandb.ai/vaknin34-hugging-face/GRPO</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250712_140315-xf7030bq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nivvaknin/Desktop/LLM-course/src/llm_course/wandb/run-20250712_140334-v7gubppe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vaknin34-hugging-face/GRPO/runs/v7gubppe' target=\"_blank\">earnest-fire-8</a></strong> to <a href='https://wandb.ai/vaknin34-hugging-face/GRPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vaknin34-hugging-face/GRPO' target=\"_blank\">https://wandb.ai/vaknin34-hugging-face/GRPO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vaknin34-hugging-face/GRPO/runs/v7gubppe' target=\"_blank\">https://wandb.ai/vaknin34-hugging-face/GRPO/runs/v7gubppe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNGuardCallback initialized. Monitoring for NaN values during training.\n",
      "Epoch started. Monitoring for NaN values during training.\n",
      "Step started. Monitoring for NaN values during training.\n",
      "Training failed with err|or: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Consider reducing batch size or learning rate further.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "wandb.init(project=\"GRPO\")\n",
    "try:\n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(f\"Training failed with err|or: {e}\")\n",
    "    print(\"Consider reducing batch size or learning rate further.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea353b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-course-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
